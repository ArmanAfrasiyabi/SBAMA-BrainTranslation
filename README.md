# Latent Representation Learning for Multimodal Brain Activity Translation
This repository contains the PyTorch implementation of the Spatiotemporal Alignment of Multimodal Brain Activity (SAMBA) framework, as described in our paper titled "Latent Representation Learning for Multimodal Brain Activity Translation." SAMBA is designed to bridge the spatial and temporal resolution gaps across neuroimaging modalities by learning a unified latent space. This approach introduces novel methods such as attention-based wavelet decomposition, graph attention networks, and recurrent layers for processing brain signals.



@article{afrasiyabi2024latent,
  title={Latent representation learning for multimodal brain activity translation},
  author={Afrasiyabi, Arman and Bhaskar, Dhananjay and Busch, Erica L and Caplette, Laurent and Singh, Rahul and Lajoie, Guillaume and Turk-Browne, Nicholas B and Krishnaswamy, Smita},
  journal={arXiv preprint arXiv:2409.18462},
  year={2024}
}
